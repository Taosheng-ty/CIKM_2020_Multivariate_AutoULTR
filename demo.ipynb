{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Multivariate Scoring Functions for Automatic Unbiased earning to Rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIrstly, we need to clone the ULTRA repo, which we create for Unbiased learning to rank. You may need to follow the instruction in https://github.com/ULTR-Community/ULTRA to install ULTRA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ULTRA'...\n",
      "remote: Enumerating objects: 164, done.\u001b[K\n",
      "remote: Counting objects: 100% (164/164), done.\u001b[K\n",
      "remote: Compressing objects: 100% (116/116), done.\u001b[K\n",
      "remote: Total 1680 (delta 94), reused 82 (delta 48), pack-reused 1516\u001b[K\n",
      "Receiving objects: 100% (1680/1680), 11.77 MiB | 22.07 MiB/s, done.\n",
      "Resolving deltas: 100% (1101/1101), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ULTR-Community/ULTRA.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/raid/taoyang/research/research_everyday/projects/CIKM2020_multivariat_ULTR/CIKM_2020_Multivariate_AutoULTR/ULTRA\n"
     ]
    }
   ],
   "source": [
    "%cd ULTRA/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The benchmark we test of our method are Yahoo set 1 and Istella\\-s. First we need to follow the instruction to download and preprocess the data accordingly. You may need to change a little bit the command line such as the download link which is dynamic and we can't set it. You need to download the datasets by yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After you download the dataset, you can run the following cmd to preprocess it.\n",
    "!bash example/Yahoo/offline_exp_pipeline.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash example/Istella-S/offline_exp_pipeline.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then we will run the experiments. You can reproduce the table and figures all by our comman line. It takes several hours to do run all experiments. We also provide slurm version comman line if you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('ultra_p36': conda)",
   "language": "python",
   "name": "python36964bitultrap36condacee6eee70e5b44b99b9b7bf023422806"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
